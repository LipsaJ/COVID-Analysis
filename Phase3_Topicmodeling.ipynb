{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-abortion",
   "metadata": {},
   "source": [
    "## Phase 3 - topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "following-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-latin",
   "metadata": {},
   "source": [
    "### COVID topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "therapeutic-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"pandemic\" + 0.005*\"people\" + 0.004*\"trump\" + 0.004*\"para\" + 0.004*\"corona\" + 0.004*\"new\" + 0.003*\"cases\" + 0.003*\"las\" + 0.003*\"virus\" + 0.002*\"china\"'),\n",
       " (1,\n",
       "  '0.008*\"pandemic\" + 0.006*\"trump\" + 0.004*\"people\" + 0.004*\"new\" + 0.003*\"cases\" + 0.003*\"para\" + 0.003*\"las\" + 0.002*\"president\" + 0.002*\"im\" + 0.002*\"contra\"'),\n",
       " (2,\n",
       "  '0.008*\"pandemic\" + 0.004*\"para\" + 0.004*\"trump\" + 0.004*\"people\" + 0.003*\"new\" + 0.003*\"las\" + 0.003*\"corona\" + 0.002*\"cases\" + 0.002*\"health\" + 0.002*\"president\"'),\n",
       " (3,\n",
       "  '0.000*\"pandemic\" + 0.000*\"people\" + 0.000*\"trump\" + 0.000*\"cases\" + 0.000*\"para\" + 0.000*\"new\" + 0.000*\"corona\" + 0.000*\"virus\" + 0.000*\"china\" + 0.000*\"las\"'),\n",
       " (4,\n",
       "  '0.007*\"pandemic\" + 0.005*\"trump\" + 0.004*\"people\" + 0.004*\"para\" + 0.003*\"new\" + 0.003*\"cases\" + 0.003*\"las\" + 0.002*\"corona\" + 0.002*\"deaths\" + 0.002*\"ms\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dat amodeling\n",
    "# make sure that you have read our document-term matrix\n",
    "data = pd.read_pickle('dtm_stop_tweets.pkl')\n",
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop_tweets.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())\n",
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-sigma",
   "metadata": {},
   "source": [
    "### vaccine topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "primary-closing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"trump\" + 0.006*\"people\" + 0.005*\"moderna\" + 0.004*\"virus\" + 0.004*\"vaccines\" + 0.003*\"going\" + 0.003*\"im\" + 0.003*\"flu\" + 0.003*\"new\" + 0.003*\"world\"'),\n",
       " (1,\n",
       "  '0.007*\"people\" + 0.006*\"moderna\" + 0.006*\"pfizer\" + 0.004*\"vaccines\" + 0.003*\"virus\" + 0.003*\"americans\" + 0.003*\"biden\" + 0.003*\"trump\" + 0.003*\"public\" + 0.003*\"im\"'),\n",
       " (2,\n",
       "  '0.000*\"trump\" + 0.000*\"moderna\" + 0.000*\"pfizer\" + 0.000*\"people\" + 0.000*\"virus\" + 0.000*\"new\" + 0.000*\"vaccines\" + 0.000*\"know\" + 0.000*\"gates\" + 0.000*\"im\"'),\n",
       " (3,\n",
       "  '0.012*\"moderna\" + 0.006*\"filha\" + 0.003*\"parents\" + 0.003*\"anti\" + 0.003*\"virus\" + 0.003*\"people\" + 0.003*\"nunca\" + 0.003*\"minha\" + 0.003*\"flu\" + 0.003*\"nenhuma\"'),\n",
       " (4,\n",
       "  '0.008*\"trump\" + 0.007*\"pfizer\" + 0.006*\"moderna\" + 0.005*\"people\" + 0.003*\"virus\" + 0.003*\"new\" + 0.003*\"im\" + 0.003*\"said\" + 0.003*\"vaccines\" + 0.003*\"pandemic\"')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dat amodeling\n",
    "# make sure that you have read our document-term matrix\n",
    "data = pd.read_pickle('dtm_stop_vaccine.pkl')\n",
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop_vaccine.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())\n",
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-purse",
   "metadata": {},
   "source": [
    "### safety topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spiritual-processor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"lockdown\" + 0.011*\"quarantine\" + 0.009*\"people\" + 0.008*\"wear\" + 0.007*\"social\" + 0.006*\"wearing\" + 0.006*\"distancing\" + 0.005*\"im\" + 0.004*\"new\" + 0.003*\"face\"'),\n",
       " (1,\n",
       "  '0.021*\"quarantine\" + 0.018*\"lockdown\" + 0.008*\"people\" + 0.008*\"social\" + 0.007*\"distancing\" + 0.005*\"im\" + 0.004*\"day\" + 0.004*\"wear\" + 0.004*\"hands\" + 0.003*\"wearing\"'),\n",
       " (2,\n",
       "  '0.001*\"lockdown\" + 0.001*\"quarantine\" + 0.001*\"people\" + 0.001*\"wear\" + 0.000*\"social\" + 0.000*\"distancing\" + 0.000*\"wearing\" + 0.000*\"new\" + 0.000*\"wash\" + 0.000*\"time\"'),\n",
       " (3,\n",
       "  '0.019*\"lockdown\" + 0.015*\"quarantine\" + 0.008*\"people\" + 0.007*\"social\" + 0.007*\"wear\" + 0.006*\"distancing\" + 0.005*\"wearing\" + 0.004*\"new\" + 0.003*\"im\" + 0.003*\"time\"'),\n",
       " (4,\n",
       "  '0.013*\"quarantine\" + 0.010*\"wash\" + 0.010*\"hands\" + 0.007*\"face\" + 0.006*\"people\" + 0.005*\"china\" + 0.004*\"wuhan\" + 0.004*\"lockdown\" + 0.004*\"handswash\" + 0.003*\"virus\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dat amodeling\n",
    "# make sure that you have read our document-term matrix\n",
    "data = pd.read_pickle('dtm_stop_safety.pkl')\n",
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop_safety.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())\n",
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-speaker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
